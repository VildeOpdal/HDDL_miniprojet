# -*- coding: utf-8 -*-
"""Final Project_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UJIPDqpJ2QJOevl2xb0KtVC4wAjFh2Vr

# Mini-project n° 1 – Qui a peint ce tableau ?

## _High-Dimensional-Deep-Learning_
5 GMM
Institut National des Sciences Appliquées de Toulouse
#### Autors:
* BUI Minh Thi
* NGUYEN Thanh Chung
* OPDAL Vilde
* VAZQUEZ ARELLANO Laura Karina
---

## Introduction
In this project, we aim to address the challenge posed by the Art Challenge dataset: identifying the artist of a given painting, avaible on https://artchallenge.ru/?lang=fr#.

This dataset provides a unique opportunity to explore high-dimensional image classification using deep learning techniques.

The dataset extracted from the site above:
Art Challenge – plmlab.math.cnrs.fr/chevallier-teaching/datasets/art-challenge, consists of:

* a file named _artists.csv_, which provides metadata about the artists, such as their biographical details, artistic styles, and the number of works included in the dataset.
* a folder _images_hq_, which has a collection of high-definition images organized by artist.
* and a folder _images_lq_, containing the same paintings in lower resolution.

To address the challenge of recognizing the artist behind a painting, we will utilize VGG16, a pre-trained convolutional neural network known for its robust performance in image classification tasks. Additionally, we will employ data augmentation techniques to enhance the diversity of our training dataset and improve model generalization. This approach allows us to effectively adapt VGG16 to our specific task while managing the potential limitations of the dataset size.

---

## Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
# Utils
import os
import shutil
import time

# Maths - Stats
import math
import sklearn
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd
import random as rd

# Data visualization
from matplotlib import pyplot as plt
# %matplotlib inline
import seaborn as sns
import PIL
from PIL import Image
import os, sys

# Deep Learning Librairies
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import GlobalAveragePooling2D
from tensorflow.keras.utils import load_img, img_to_array
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, save_img

tf.config.list_physical_devices()
[k.device_type for k in tf.config.list_physical_devices()]

"""## Dataset
As explained in the introduction, the dataset used in this project was extracted from the site above: Art Challenge – plmlab.math.cnrs.fr/chevallier-teaching/datasets/art-challenge
"""

!git clone https://plmlab.math.cnrs.fr/chevallier-teaching/datasets/art-challenge.git

"""Our data is organized this way :

```
 art-challenge
└─── images_hq/
│   └───Albrecht_Dürer /
│   │   │   Albrecht_Dürer_1.jpg
│   │   │   Albrecht_Dürer_10.jpg
│   │   │   ...
│   └───Alfred_Sisley /
│   │   │   Alfred_Sisley_1.jpg
│   │   │   Alfred_Sisley_10.jpg
│   │   │   ...
│   │   ...
└─── images_lq/
│   │   Albrecht_Dürer_1.jpg
│   │   Albrecht_Dürer_10.jpg
│   │   ...
│   │   Alfred_Sisley_1.jpg
│   │   Alfred_Sisley_10.jpg
│   │   ...
```
"""

# Path to the datasets
path = "./art-challenge/"

"""##### Displaying and comparing a high and low definition image of the dataset </i>"""

img = plt.imread('art-challenge/images_hq/Albrecht_Dürer/Albrecht_Dürer_1.jpg')
plt.imshow(img)
plt.title('High-quality version')
plt.show()
print ('Image shape: ',img.shape[-1])

img = plt.imread('art-challenge/images_lq/Albrecht_Dürer_1.jpg')
plt.imshow(img)
plt.title('Low-quality version')
plt.show()
print ('Image shape: ',img.shape[-1])

"""The output 432 from img.shape[-1] suggests that img is likely not loaded as a standard 3- or 4-channel image array but may instead represent a flattened or reshaped array. This might happen if Matplotlib or the image library misinterprets the file format.

To handdle the issue we will convert to an RGB array if necessary:
"""

def load_and_display_image(image_path, quality):
    """
    Load an image, convert to RGB if necessary, and display it using Matplotlib.

    Parameters:
    - image_path (str): The file path to the image.
    """
    img_pil = Image.open(image_path)
    img = np.array(img_pil.convert("RGB"))

    plt.imshow(img)
    plt.axis('off')
    if quality == 'hq' :
      plt.title('High-quality version')
    if quality == 'lq':
      plt.title('Low-quality version')

    plt.show()
    print ('Image shape: ',img.shape[-1])

load_and_display_image('art-challenge/images_hq/Albrecht_Dürer/Albrecht_Dürer_1.jpg', 'hq')

load_and_display_image('art-challenge/images_lq/Albrecht_Dürer_1.jpg', 'lq')

"""Chosen images to study

Given that the quality difference between high- and low-quality images appears minimal to the human eye, we decided to use the low-quality images. The idea is to leverage the low-resolution dataset for finding a suitable model architecture and hyperparameters, then potentially fine-tune the model on high-quality images if necessary.

This approach is justified by the fact that VGG16 reduces the input image into a latent space representation through successive convolutional and pooling layers. These layers focus on extracting high-level features such as edges, shapes, and textures, rather than preserving fine details in the input image. Consequently, the additional information in high-quality images may not significantly impact the model’s performance, especially for tasks like artist classification, where distinguishing features are often captured at a higher abstraction level.

By working with low-quality images, we reduce computational costs and memory usage without sacrificing the effectiveness of the feature extraction process, making this approach both efficient and practical.

##### Distribution of paints per artist
"""

image_folder = "./art-challenge/images_lq/"
image_data = []


for image_name in os.listdir(image_folder):
    if image_name.endswith(".jpg"):
        # Extract artist name from the file name (e.g., "Albrecht_Dürer_1.jpg" -> "Albrecht_Dürer")
        artist_name = "_".join(image_name.split("_")[:-1])
        image_data.append({
            'filename': image_name,
            'label': artist_name
        })

        img_path = os.path.join(image_folder, image_name)
        img = load_img(img_path)

# Create Data DataFrame with 'filename' and 'label' columns
Data = pd.DataFrame(image_data)
print(Data.head(5))
print('--------------------------')
print(f"Total number of images: {len(Data)}")

def plot_distribution(data, title):
    counts = data['label'].value_counts()
    plt.figure(figsize=(14, 7))
    counts.plot(kind='bar')
    plt.title(title)
    plt.xlabel('Artist')
    plt.ylabel('Number of Images')
    plt.xticks(rotation=90)
    plt.tight_layout()
    plt.show()

plot_distribution(Data, "Original Data Distribution")

"""The plot "Original Data Distribution" reveals that a few artists, such as Vincent Van Gogh and Edgar Degas, have a disproportionately large number of paintings (over 600), while many other artists are represented with only around 150 paintings.

#### Applying truncation rules

A balanced dataset is essential to prevent the model from overfitting to the works of a few artists and underperforming on those of others.

To address this imbalance, we decided to apply two measures: first, we excluded artists with fewer than 150 images, and second, we capped the maximum number of images per artist at 200. This approach ensures a more uniform distribution of data across all classes, which is crucial for training a fair and effective model.
"""

min_images = 150
max_images = 200

# Filter out artists with insufficient images
artist_counts = Data['label'].value_counts()
filtered_artists = artist_counts[(artist_counts >= min_images) & (artist_counts <= max_images)].index

# Filter the dataset
Data_truncated = Data[Data['label'].isin(filtered_artists)].copy()

# Truncate artists with too many images
for artist in artist_counts[artist_counts > max_images].index:
    # Keep only a random sample of `max_images`
    artist_data = Data[Data['label'] == artist]
    sampled_data = artist_data.sample(max_images, random_state=42)
    Data_truncated = pd.concat([Data_truncated, sampled_data])

# Plot the truncated data distributioAmedeo_Modiglianin
plot_distribution(Data_truncated, "Truncated Data Distribution")

"""After applying these rules, we retained 18 artists, who will subsequently serve as our classification labels."""

# Print the size of the truncated dataset
print(f"Size of Data_truncated: {len(Data_truncated)}")
print(f"Shape of Data_truncated: {Data_truncated.shape}")
num_unique_labels = Data_truncated['label'].nunique()
print(f"Number of unique labels (artists): {num_unique_labels}")
print(Data_truncated.head(5))

"""#### Creation of Dataframe
Split Data into train (70%), validation (15%), and test (15%) sets.
"""

train_df, temp_df = train_test_split(Data_truncated, test_size=0.3, stratify=Data_truncated['label'], random_state=42)
validation_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)

"""#### Organizing images into separate folders

"""

base_dir = "./art_challenge_dataset/"
os.makedirs(base_dir, exist_ok=True)

def organize_data(df, subset_name):
    # Create the main directory for the subset (train/validation/test)
    subset_dir = os.path.join(base_dir, subset_name)
    os.makedirs(subset_dir, exist_ok=True)

    # Create a directory to hold all images (not artist-specific)
    all_images_dir = os.path.join(subset_dir, "all_images")
    os.makedirs(all_images_dir, exist_ok=True)

    # Loop through the dataset and copy each image to the appropriate directory
    for _, row in df.iterrows():
        # Organize by artist (individual artist folders)
        artist_dir = os.path.join(subset_dir, row['label'])
        os.makedirs(artist_dir, exist_ok=True)

        # Copy the image to the artist-specific folder
        src_path = os.path.join(image_folder, row['filename'])
        dst_path = os.path.join(artist_dir, row['filename'])
        shutil.copy(src_path, dst_path)

        # Copy the image to the all_images folder
        dst_path_all_images = os.path.join(all_images_dir, os.path.basename(row['filename']))
        shutil.copy(src_path, dst_path_all_images)

organize_data(train_df, "train1")
organize_data(validation_df, "validation1")
organize_data(test_df, "test1")

"""Our data is now organized this way :

```
 /art_challenge_dataset
└─── train1/
│   └───Albrecht_Dürer /
│   │   │   Albrecht_Dürer_1.jpg
│   │   │   Albrecht_Dürer_10.jpg
│   │   │   ...
│   └───Alfred_Sisley /
│   │   │   Alfred_Sisley_1.jpg
│   │   │   Alfred_Sisley_10.jpg
│   │   │   ...
│   │   ...
│   │   all_images /
│   │   │   Alfred_Sisley_1.jpg
│   │   │   Alfred_Sisley_10.jpg
│   │   │   ...
└─── validation1/
│   └───Albrecht_Dürer /
│   │   │   Albrecht_Dürer_1.jpg
│   │   │   Albrecht_Dürer_10.jpg
│   │   │   ...
│   └───Alfred_Sisley /
│   │   │   Alfred_Sisley_1.jpg
│   │   │   Alfred_Sisley_10.jpg
│   │   │   ...
│   │   ...
│   │   all_images /
│   │   │   Alfred_Sisley_1.jpg
│   │   │   Alfred_Sisley_10.jpg
│   │   │   ...
└─── test1/
│   └───Albrecht_Dürer /
│   │   │   Albrecht_Dürer_1.jpg
│   │   │   Albrecht_Dürer_10.jpg
│   │   │   ...
│   └───Alfred_Sisley /
│   │   │   Alfred_Sisley_1.jpg
│   │   │   Alfred_Sisley_10.jpg
│   │   │   ...
│   │   ...
│   │   all_images /
│   │   │   Alfred_Sisley_1.jpg
│   │   │   Alfred_Sisley_10.jpg
│   │   │   ...
```
"""

total_train0 = train_df.shape[0]
total_validation0 = validation_df.shape[0]
total_test0 = test_df.shape[0]

print("We have %d training data, %d validation data and %d test data, all labels (artists) combined." %
      (total_train0, total_validation0, total_test0))

# Check distribution of images by artist in each set
train_counts = train_df['label'].value_counts()
validation_counts = validation_df['label'].value_counts()
test_counts = test_df['label'].value_counts()

# Display distribution counts for each artist in train, validation, and test sets
print("Training set distribution:\n", train_counts)
#print("\nValidation set distribution:\n", validation_counts)
#print("\nTest set distribution:\n", test_counts)

"""Balancing only the training dataset :"""

from sklearn.utils import resample

# Oversample the minority classes in training data
max_samples = train_counts.max()  # Target sample size for each class
oversampled_dfs = []

for label, count in train_counts.items():
    class_df = train_df[train_df['label'] == label]
    oversampled_class_df = resample(class_df, replace=True, n_samples=max_samples, random_state=42)
    oversampled_dfs.append(oversampled_class_df)

# Combine all oversampled data
balanced_train_df = pd.concat(oversampled_dfs)

# Verify new class distribution
print(balanced_train_df['label'].value_counts())

"""Reset the index of the balanced DataFrame to ensure indices are sequential :"""

balanced_train_df = balanced_train_df.reset_index(drop=True)
balanced_train_df[balanced_train_df['label'] == "Andy_Warhol"].head(-5)

total_train = balanced_train_df.shape[0]
total_validation = validation_df.shape[0]
total_test = test_df.shape[0]

print("We have %d training data, %d validation data and %d test data, all labels (artists) combined." %
      (total_train, total_validation, total_test))

path_dataset = "./art_challenge_dataset/"

"""## Pre-processing

#### Fluctuations in image shapes

We consider the fluctuations in image shapes within the dataset. Images vary in dimensions, which can introduce inconsistencies during training.
"""

from collections import Counter
heights = []
widths = []

for filename in Data_truncated['filename']:
    img_path = os.path.join(image_folder, filename)
    img = load_img(img_path)
    widths.append(img.size[0])
    heights.append(img.size[1])

dimension_h_counter = Counter(heights)
dimension_w_counter = Counter(widths)

most_common_h_dimension = dimension_h_counter.most_common(1)[0]
most_common_w_dimension = dimension_w_counter.most_common(1)[0]


print(f"Most common heigth : {most_common_h_dimension[0]} pixels ({most_common_h_dimension[1]} occurrences)")
print(f"Most common width : {most_common_w_dimension[0]} pixels ({most_common_w_dimension[1]} occurrences)")


plt.figure(figsize=(12, 6))


plt.subplot(1, 2, 1)
plt.hist(heights, bins=30, color='skyblue', edgecolor='black')
plt.title("Histogram of images heigth (Data_truncated)")
plt.xlabel("Heigth (pixels)")
plt.ylabel("Number of Images")


plt.subplot(1, 2, 2)
plt.hist(widths, bins=30, color='lightgreen', edgecolor='black')
plt.title("Histogram of images width (Data_truncated)")
plt.xlabel("Width (pixels)")
plt.ylabel("Number of Images")


plt.tight_layout()
plt.show()

"""As we see in both histograms, images in the dataset have varying dimensions, which poses a challenge as neural networks require consistent input sizes. To address this, we need to resize all images to a common dimension.

When choosing the target size, a smaller resolution like \(64 x 64\) might allow for quicker experimentation but could compromise the model's ability to capture detailed features. Conversely, larger sizes like \(128 x 128\) or \(256 x 256\) would likely yield better results but require significantly longer training times.

Considering these trade-offs, we selected \(224 x 224\) as the target image size. This dimension aligns with the input requirements of the VGG16 architecture, which is pretrained on images of this size. Additionally, we applied a normalization step by dividing pixel values by 255 to scale them to the range [0, 1], ensuring compatibility with the preprocessing used during VGG16's training.

#### Resizing and normalization
"""

batch_size = 32
img_width = 224
img_height = 224

"""To ensure stability and consistency during training, the batch size must divide evenly into the number of training (N_train) and validation (N_validation) samples. If this condition is not met, it can result in incomplete batches, which may lead to issues during optimization or evaluation.

To address this, we opted to set `drop_remainder=True` in our data generators. This configuration discards any remaining images that do not fit into a complete batch. While this approach slightly reduces the size of the training and validation datasets, it ensures that all batches are uniform, thereby maintaining stability during the training process.
"""

path_dataset = "./art_challenge_dataset/"

# Training images
train_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_dataframe(
    balanced_train_df,
    directory=path_dataset + "train1/all_images/",
    x_col='filename',
    y_col='label',
    target_size=(img_width, img_height),
    interpolation="bilinear",
    class_mode='categorical',
    batch_size=batch_size,
    drop_remainder=True  # Ensures batches are full

)

# Validation images
validation_datagen = ImageDataGenerator(rescale=1./255)
validation_generator = validation_datagen.flow_from_dataframe(
    validation_df,
    directory=path_dataset + "validation1/all_images/",
    x_col='filename',
    y_col='label',
    target_size=(img_width, img_height),
    interpolation="bilinear",
    class_mode='categorical',
    batch_size=batch_size,
    drop_remainder=True  # Ensures batches are full
)

# Test images
test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_dataframe(
    test_df,
    directory=path_dataset + "test1/all_images/",
    x_col='filename',
    y_col='label',
    target_size=(img_width, img_height),
    interpolation="bilinear",
    class_mode='categorical',
    batch_size=batch_size,
    drop_remainder=True  # Ensures batches are full

)

print(f"Number of batches for training : {train_generator.samples // batch_size}")
print(f"Number of batches for validation : {validation_generator.samples // batch_size}")
print(f"Number of batches for test : {test_generator.samples // batch_size}")

"""To better understand the training dataset, we visualize a sample of nine images generated by the train_generator. Each image is accompanied by its corresponding artist's name, which serves as the class label. The plot above allows us to confirm that the preprocessing steps, including resizing and normalization, have been correctly applied. It also provides a sense of the diversity in artistic styles and content represented in the dataset, contributing to a more intuitive understanding of the data our model will learn from."""

plt.figure(figsize=(12, 12))

for i in range(9):
    plt.subplot(3, 3, i+1)
    for x_batch, y_batch in train_generator:
        img = x_batch[0]
        # Get the index of the class from the one-hot encoded label
        label_index = np.argmax(y_batch[0])
        artist_name = list(train_generator.class_indices.keys())[label_index]

        plt.title(artist_name)
        plt.imshow(img)
        plt.axis('off')
        plt.grid(False)
        break

plt.tight_layout()
plt.show()

"""## Data augmentation

To enhance the diversity of our training data and improve the model's generalization capabilities, we apply data augmentation techniques.

We generate five augmented versions of each image using several augmentation techniques, including random rotations, translations, shearing, zooming, and horizontal flipping. These augmentations introduce variability to the training data, simulating real-world conditions and mitigating overfitting.

Before generating augmented images, we copy the original training images to the new directory. This ensures that both the original and augmented images are included in the training dataset.
"""

IMAGE_SIZE = 224
from tensorflow.keras.preprocessing.image import ImageDataGenerator

image_folder_train="./art_challenge_dataset/train1/all_images"
augmented_train_dir = "./art_challenge_dataset/augmented_train_images/"
os.makedirs(augmented_train_dir, exist_ok=True)

datagen = ImageDataGenerator(
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Copy original training images to augmented_train_dir
for index, row in train_df.iterrows():
    original_path = os.path.join(image_folder_train, row['filename'])
    shutil.copy(original_path, os.path.join(augmented_train_dir, row['filename']))

# Generate augmented images for training data
for index, row in train_df.iterrows():
    img_path = os.path.join(image_folder_train, row['filename'])
    img = load_img(img_path, target_size=(IMAGE_SIZE, IMAGE_SIZE))
    img_array = img_to_array(img)
    img_array = img_array.reshape((1,) + img_array.shape)

    i = 0
    for batch in datagen.flow(
        img_array,
        batch_size=1,
        save_to_dir=augmented_train_dir,
        save_prefix="_".join(row['filename'].split(".")[:-1]),
        save_format='jpg'
    ):
        i += 1
        if i >= 5:  # Generate 5 augmentations per image
            break

print("Training dataset enriched with augmented images.")

"""Here is an exemple of an original image and the 5 augmented images created from it."""

example_img_path = os.path.join(image_folder_train, Data_truncated.iloc[10]['filename'])
example_img = load_img(example_img_path, target_size=(IMAGE_SIZE, IMAGE_SIZE))
example_array = img_to_array(example_img)
example_array = example_array.reshape((1,) + example_array.shape)

# Générer et afficher les augmentations
fig, axes = plt.subplots(1, 6, figsize=(15, 5))
axes[0].imshow(example_img)
axes[0].set_title("Original")
axes[0].axis("off")
print(f"Name of the original image : {Data_truncated.iloc[10]['filename']}")
i = 1
for batch in datagen.flow(example_array, batch_size=1):
    augmented_img = batch[0].astype('uint8')
    axes[i].imshow(augmented_img)
    axes[i].set_title(f"Augmented {i}")
    axes[i].axis("off")
    i += 1
    if i >= 6:  # Limiter à 5 augmentations
        break

plt.tight_layout()
plt.show()

"""Considering the augmented training images, we generate a DataFrame associating each image with its respective label. The process ensures that the augmented images are correctly organized for further training."""

import re

image_folder = augmented_train_dir
image_data = []

for image_name in os.listdir(image_folder):
    if image_name.endswith(".jpg"):
        # Extract the label using a regex: capture everything before _ and a digit
        # Example : Albrecht_Dürer_100_0_9548.jpg -> label = Albrecht_Dürer
        # Example : Titan_10.jpg -> label = Titan
        match = re.match(r"^(.*?)(?=_[0-9])", image_name)
        if match:
            artist_name = match.group(1)
        else:
            artist_name = "unknown"
        image_data.append({
            'filename': image_name,
            'label': artist_name
        })


train_generator_augmented = pd.DataFrame(image_data)
print('DataFrame : train_generator_augmented')
print(train_generator_augmented.head())
label_counts = train_generator_augmented['label'].value_counts()
print('-------------------------------------------------------------')
print(label_counts)

"""Next, we create a generator from augmented training data.

"""

train_generator = train_datagen.flow_from_dataframe(
    train_generator_augmented,
    directory=augmented_train_dir,
    x_col='filename',
    y_col='label',
    target_size=(img_width, img_height),
    class_mode='categorical',
    batch_size=batch_size,
    drop_remainder=True  # Ensures batches are full
)

"""## Pre-trained Network

In this project, we use the VGG16 neural network, a pre-trained architecture for classification learning.

VGG16 is composed of 13 convolutional layers, 5 max-pooling layers, and 3 fully connected layers. Therefore, the number of layers having tunable parameters is 16 (13 convolutional layers and 3 fully connected layers). That is the reason why the model name is VGG16.

_Source : https://lekhuyen.medium.com/an-overview-of-vgg16-and-nin-models-96e4bf398484_

![VGG16.webp](data:image/webp;base64,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)

_Source: Researchgate.net_

The convolutional base of VGG16 is used for feature extraction, as it contains layers specifically designed to capture hierarchical patterns in images, such as edges, textures, and more complex structures. By excluding the fully connected layers at the top of the original architecture, we ensure flexibility in adapting the network to our specific classification task.

For this project, we set the input size to 224×224 pixels, the standard input dimensions for VGG16, as mencioned before. This ensures compatibility with the pre-trained model while allowing us to incorporate additional layers tailored to the classification of the 18 artists in our dataset.
"""

from tensorflow.keras.applications import VGG16

conv_base = VGG16(
    weights = 'imagenet', # We use the network weights already pre-trained on the ImageNet database.
    include_top = False,  # The Fully Connected part of the original network is not retained
    input_shape = (img_width, img_height, 3)
)

conv_base.summary()

"""After defining the convolutional base of the pre-trained VGG16 model for feature extraction, we construct a custom architecture by adding fully connected layers tailored to our classification task. This step allows us to adapt the pre-trained features to distinguish between the 18 artists in our dataset.

The added architecture includes:

* Global Average Pooling

Converts the spatial feature maps from the convolutional base into a fixed-length vector, summarizing the information from each feature map while reducing the number of parameters compared to a fully connected layer.

* Dense layers

Two Dense layers with 256 units each and ReLU activation to learn complex patterns in the extracted features.

* Dropout layers

Dropout layers prevent overfitting by randomly deactivating a fraction of neurons during training.

* Output Layer

A Dense layer with a softmax activation function and a number of units equal to the number of classes (18 in this case), providing probabilities for each artist.
"""

from tensorflow.keras import models, layers

def model_vgg(input_shape, num_classes):
    model = models.Sequential()
    model.add(conv_base)
    model.add(GlobalAveragePooling2D())
    model.add(layers.Flatten())
    model.add(layers.Dense(256, activation='relu'))
    model.add(layers.Dropout(0.5))
    model.add(layers.Dense(256, activation='relu'))
    model.add(layers.Dropout(0.5))
    model.add(layers.Dense(num_classes, activation='softmax'))

    return model

"""We configure the optimization strategy and incorporating an optimizer and a learning rate scheduler during training:

* Optimizer

We use the Adam optimizer which is a popular choice for deep learning tasks because it combines the advantages of two other extensions of stochastic gradient descent (SGD): adaptive gradient (AdaGrad) and root mean square propagation (RMSProp). This helps the model converge faster and efficiently handle sparse gradients.

* Learning Rate Scheduler

A ReduceLROnPlateau callback is included to monitor the validation loss and reduce the learning rate dynamically if the loss stops improving.
"""

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ReduceLROnPlateau

reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-10)
opt = Adam(learning_rate=3e-4)

num_classes = 18
model = model_vgg(input_shape=(img_width, img_height, 3), num_classes=num_classes)

# Phase 1: Transfert d'apprentissage
conv_base.trainable = False  # We freeze the VGG16 base
model.compile(loss='categorical_crossentropy',
              optimizer=opt,
              metrics=['accuracy'])

# Training
epochs = 30
batch_size = 32

history_1 = model.fit(
    train_generator,
    epochs=epochs,
    batch_size=batch_size,
    validation_data=validation_generator,
    callbacks=reduce_lr
)

def plot_training_analysis(history):
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']
    loss = history.history['loss']
    val_loss = history.history['val_loss']

    epochs = range(len(acc))

    plt.subplot(1,2,1)
    plt.plot(epochs, acc, 'b', linestyle="--",label='Training accuracy')
    plt.plot(epochs, val_acc, 'g', label='Validation accuracy')
    plt.title('Training and validation accuracy')
    plt.legend()

    plt.subplot(1,2,2)
    plt.plot(epochs, loss, 'b', linestyle="--",label='Training loss')
    plt.plot(epochs, val_loss,'g', label='Validation loss')
    plt.title('Training and validation loss')
    plt.legend()

    plt.tight_layout()
    plt.show()

plot_training_analysis(history_1)

"""We observe that the accuracy and loss could continue evolving.
We will now apply the second phase: fine-tunning.
"""

# Phase 2: Fine-tuning
fine_epochs = 20
conv_base.trainable = True  # On dégèle les couches de VGG16

# Réduire le learning rate pour le fine-tuning
opt = Adam(learning_rate=1e-6)

model.compile(loss='categorical_crossentropy',
              optimizer=opt,
              metrics=['accuracy'])

history_2 = model.fit(
    train_generator,
    epochs=fine_epochs,
    batch_size=batch_size,
    validation_data=validation_generator,
    callbacks=reduce_lr #[early_stopping, reduce_lr]
)

plot_training_analysis(history_2)

"""After fine-tunning, the accuracy and loss are better fitted. We achieved a test accuracy of 87.76% on the training set and a validation accuracy of 70.50%

## Prediction

After completing the training and validation process, we test the model on a separate test dataset that it has never seen before. This helps us assess its ability to generalize to new, unseen data.

By comparing the predicted labels with the ground truth, we compute the model's accuracy on the test set, providing a quantitative measure of its performance.

 To better understand the model's predictions, we randomly select a subset of test images and display them with their predicted and true labels. This qualitative assessment allows us to visually inspect where the model performs well or makes mistakes.  

 A green title means that the prediction is correct while a red one means it is incorrect.
"""

test_prediction = model.predict(test_generator)  # Probabilities for the 18 classes
score_test = model.evaluate(test_generator)
print('Test accuracy:', score_test[1])

fig = plt.figure(figsize=(12, 12))

#Selecting 9 random images
test_imgs_idx = np.random.randint(low=0, high=len(test_generator.filenames), size=(9,))

for i, idx in enumerate(test_imgs_idx):
    img_path = test_generator.filepaths[idx]
    img = img_to_array(load_img(img_path, target_size=(img_width, img_height))) / 255.0

    pred = test_prediction[idx]
    predicted_class_index = np.argmax(pred)
    predicted_class_name = list(test_generator.class_indices.keys())[predicted_class_index]

    true_class_index = test_generator.labels[idx]
    true_class_name = list(test_generator.class_indices.keys())[true_class_index]

    color = "green" if predicted_class_name == true_class_name else "red"
    title = f"Prédit: {predicted_class_name}\nVrai: {true_class_name}"

    ax = fig.add_subplot(3, 3, i + 1)
    ax.imshow(img)
    ax.axis('off')
    ax.set_title(title, color=color)

plt.tight_layout()
plt.show()

test_prediction = model.predict(test_generator)  # Probabilities for the 18 classes
score_test = model.evaluate(test_generator)
print('Test accuracy:', score_test[1])

fig = plt.figure(figsize=(12, 12))

#Selecting 9 random images
test_imgs_idx = np.random.randint(low=0, high=len(test_generator.filenames), size=(9,))

for i, idx in enumerate(test_imgs_idx):
    img_path = test_generator.filepaths[idx]
    img = img_to_array(load_img(img_path, target_size=(img_width, img_height))) / 255.0

    pred = test_prediction[idx]
    predicted_class_index = np.argmax(pred)
    predicted_class_name = list(test_generator.class_indices.keys())[predicted_class_index]

    true_class_index = test_generator.labels[idx]
    true_class_name = list(test_generator.class_indices.keys())[true_class_index]

    color = "green" if predicted_class_name == true_class_name else "red"
    title = f"Prédit: {predicted_class_name}\nVrai: {true_class_name}"

    ax = fig.add_subplot(3, 3, i + 1)
    ax.imshow(img)
    ax.axis('off')
    ax.set_title(title, color=color)

plt.tight_layout()
plt.show()

test_prediction = model.predict(test_generator)  # Probabilities for the 18 classes
score_test = model.evaluate(test_generator)
print('Test accuracy:', score_test[1])

fig = plt.figure(figsize=(12, 12))

#Selecting 9 random images
test_imgs_idx = np.random.randint(low=0, high=len(test_generator.filenames), size=(9,))

for i, idx in enumerate(test_imgs_idx):
    img_path = test_generator.filepaths[idx]
    img = img_to_array(load_img(img_path, target_size=(img_width, img_height))) / 255.0

    pred = test_prediction[idx]
    predicted_class_index = np.argmax(pred)
    predicted_class_name = list(test_generator.class_indices.keys())[predicted_class_index]

    true_class_index = test_generator.labels[idx]
    true_class_name = list(test_generator.class_indices.keys())[true_class_index]

    color = "green" if predicted_class_name == true_class_name else "red"
    title = f"Prédit: {predicted_class_name}\nVrai: {true_class_name}"

    ax = fig.add_subplot(3, 3, i + 1)
    ax.imshow(img)
    ax.axis('off')
    ax.set_title(title, color=color)

plt.tight_layout()
plt.show()

"""## Conclusion

In this project, we successfully built and fine-tuned a deep learning model to classify the artists of paintings using a pre-trained VGG16 architecture. By leveraging data augmentation and pre-processing techniques, we managed to improve the performance of the model despite the challenges posed by an imbalanced dataset and the variation in image quality.

After fine-tuning the VGG16 model with a learning rate reduction strategy, we achieved a test accuracy of 87.76% on the training set and a validation accuracy of 70.50%. This shows that the model is able to classify the artist of a painting with a reasonable degree of accuracy, though there is still room for improvement.
"""